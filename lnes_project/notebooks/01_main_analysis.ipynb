{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Analysis: MacroMind (LNES) Experiment\n",
    "\n",
    "This notebook demonstrates a complete end-to-end analysis of the Latent News Event Simulation (LNES) system using the small dataset.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup & Configuration](#setup)\n",
    "2. [Data Loading & Exploration](#data)\n",
    "3. [News Embedding](#embedding)\n",
    "4. [Clustering Analysis](#clustering)\n",
    "5. [Agent Initialization](#agents)\n",
    "6. [Market Simulation](#simulation)\n",
    "7. [Performance Metrics](#metrics)\n",
    "8. [Visualization](#visualization)\n",
    "9. [Key Takeaways](#takeaways)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook walks through all stages of the LNES pipeline:\n",
    "- Load news and price data\n",
    "- Embed news text using TF-IDF or transformers\n",
    "- Cluster news into latent event categories\n",
    "- Initialize trading agents (rule-based and AI)\n",
    "- Simulate market dynamics\n",
    "- Evaluate performance with quantitative metrics\n",
    "- Visualize results\n",
    "\n",
    "**Dataset**: Small curated dataset (~100 rows)  \n",
    "**Configuration**: `config/small_dataset.yaml`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import notebook utilities (includes all necessary imports)\n",
    "from notebook_utils import *\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print_section(\"MacroMind Main Analysis\", \"=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = load_config(\"small_dataset\")\n",
    "\n",
    "print(\"Configuration loaded successfully!\")\n",
    "print(f\"\\nExperiment: {config['experiment']['name']}\")\n",
    "print(f\"Dataset: {config['dataset']['type']}\")\n",
    "print(f\"Embedder: {config['embedder']['backend']}\")\n",
    "print(f\"Clustering K: {config['clustering']['k']}\")\n",
    "print(f\"Agents: {', '.join(config['agents']['enabled'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data'></a>\n",
    "## 2. Data Loading & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "news_df, prices_df = load_smallset()\n",
    "\n",
    "print(f\"Loaded {len(news_df)} news items\")\n",
    "print(f\"Loaded {len(prices_df)} price records\")\n",
    "print(f\"\\nDate range: {prices_df['date'].min()} to {prices_df['date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore news data\n",
    "print_subsection(\"News Data Sample\")\n",
    "display(news_df.head())\n",
    "\n",
    "print(f\"\\nColumns: {list(news_df.columns)}\")\n",
    "print(f\"Text length stats: min={news_df['text'].str.len().min()}, \"\n",
    "      f\"max={news_df['text'].str.len().max()}, \"\n",
    "      f\"mean={news_df['text'].str.len().mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore price data\n",
    "print_subsection(\"Price Data Sample\")\n",
    "display(prices_df.head())\n",
    "\n",
    "# Plot price series\n",
    "fig, ax = plt.subplots(figsize=FIGSIZE_WIDE)\n",
    "ax.plot(prices_df['date'], prices_df['close'], label='Close Price', linewidth=2)\n",
    "ax.set_title('Historical Price Series')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Price')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='embedding'></a>\n",
    "## 3. News Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedder\n",
    "embedder = NewsEmbedder(backend=config['embedder']['backend'])\n",
    "\n",
    "print(f\"Embedder backend: {embedder.backend}\")\n",
    "print(\"Embedding news text...\")\n",
    "\n",
    "# Embed news\n",
    "embeddings = embedder.embed(news_df['text'].tolist())\n",
    "\n",
    "print(f\"✓ Generated embeddings of shape: {embeddings.shape}\")\n",
    "print(f\"  Embedding dimension: {embeddings.shape[1]}\")\n",
    "print(f\"  Number of embeddings: {embeddings.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clustering'></a>\n",
    "## 4. Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering\n",
    "k = config['clustering']['k']\n",
    "clustering = NewsClustering(k=k)\n",
    "clusters = clustering.fit_predict(embeddings)\n",
    "\n",
    "print(f\"✓ Created {k} clusters\")\n",
    "print(f\"  Silhouette score: {clustering.silhouette_score(embeddings):.3f}\")\n",
    "\n",
    "# Cluster distribution\n",
    "unique, counts = np.unique(clusters, return_counts=True)\n",
    "print(f\"\\nCluster distribution:\")\n",
    "for cluster_id, count in zip(unique, counts):\n",
    "    print(f\"  Cluster {cluster_id}: {count} items ({count/len(clusters)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters\n",
    "fig = plot_cluster_analysis(embeddings, clusters, method='tsne')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample news from each cluster\n",
    "print_subsection(\"Sample News from Each Cluster\")\n",
    "\n",
    "for cluster_id in range(k):\n",
    "    cluster_indices = np.where(clusters == cluster_id)[0]\n",
    "    sample_idx = cluster_indices[0]  # Take first item\n",
    "    sample_text = news_df.iloc[sample_idx]['text'][:200]  # First 200 chars\n",
    "    \n",
    "    print(f\"\\n[Cluster {cluster_id}] ({len(cluster_indices)} items)\")\n",
    "    print(f\"  {sample_text}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='agents'></a>\n",
    "## 5. Agent Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agents\n",
    "agents = []\n",
    "agent_names = config['agents']['enabled']\n",
    "\n",
    "for agent_name in agent_names:\n",
    "    if agent_name == 'Random':\n",
    "        agents.append(Random())\n",
    "    elif agent_name == 'Momentum':\n",
    "        agents.append(Momentum())\n",
    "    elif agent_name == 'Contrarian':\n",
    "        agents.append(Contrarian())\n",
    "    elif agent_name == 'NewsReactive':\n",
    "        agents.append(NewsReactive(clusters=clusters, k=k))\n",
    "\n",
    "print(f\"✓ Initialized {len(agents)} agents:\")\n",
    "for i, agent in enumerate(agents):\n",
    "    print(f\"  {i+1}. {agent.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='simulation'></a>\n",
    "## 6. Market Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simulator\n",
    "simulator = MarketSimulator(\n",
    "    agents=agents,\n",
    "    alpha=config['simulator']['alpha'],\n",
    "    noise_std=config['simulator']['noise_std']\n",
    ")\n",
    "\n",
    "print(f\"Simulator configuration:\")\n",
    "print(f\"  Alpha (price impact): {simulator.alpha}\")\n",
    "print(f\"  Noise std: {simulator.noise_std}\")\n",
    "print(f\"  Number of agents: {len(simulator.agents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation\n",
    "print(\"\\nRunning market simulation...\")\n",
    "sim_prices, action_log = simulator.simulate(\n",
    "    news_df=news_df,\n",
    "    prices_df=prices_df,\n",
    "    clusters=clusters\n",
    ")\n",
    "\n",
    "print(f\"✓ Simulation complete!\")\n",
    "print(f\"  Simulated {len(sim_prices)} time steps\")\n",
    "print(f\"  Price range: [{sim_prices.min():.2f}, {sim_prices.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='metrics'></a>\n",
    "## 7. Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics\n",
    "ref_prices = prices_df['close'].values\n",
    "\n",
    "print_subsection(\"Performance Metrics\")\n",
    "\n",
    "# Directional accuracy\n",
    "dir_acc = metrics.directional_accuracy(ref_prices, sim_prices)\n",
    "print(f\"Directional Accuracy: {dir_acc:.2%}\")\n",
    "\n",
    "# Volatility clustering\n",
    "vol_clust = metrics.volatility_clustering(sim_prices)\n",
    "print(f\"Volatility Clustering (lag=5): {vol_clust:.3f}\")\n",
    "\n",
    "# Cluster-price correlation\n",
    "cluster_price_corr = metrics.cluster_price_correlation(clusters, ref_prices)\n",
    "print(f\"Cluster-Price Correlation: {cluster_price_corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced metrics (if enabled)\n",
    "if config['metrics']['advanced_metrics']:\n",
    "    print_subsection(\"Advanced Metrics\")\n",
    "    \n",
    "    # Sharpe ratio\n",
    "    sharpe = metrics.sharpe_ratio(sim_prices, \n",
    "                                  risk_free_rate=config['metrics']['risk_free_rate'])\n",
    "    print(f\"Sharpe Ratio: {sharpe:.3f}\")\n",
    "    \n",
    "    # Maximum drawdown\n",
    "    max_dd = metrics.maximum_drawdown(sim_prices)\n",
    "    print(f\"Maximum Drawdown: {max_dd:.2%}\")\n",
    "    \n",
    "    # Sortino ratio\n",
    "    sortino = metrics.sortino_ratio(sim_prices, \n",
    "                                   risk_free_rate=config['metrics']['risk_free_rate'])\n",
    "    print(f\"Sortino Ratio: {sortino:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent performance\n",
    "print_subsection(\"Agent Performance\")\n",
    "\n",
    "# PnL\n",
    "pnl = metrics.agent_pnl(action_log, ref_prices)\n",
    "print(\"\\nAgent PnL (Naive):\")\n",
    "for agent_name, pnl_value in pnl.items():\n",
    "    print(f\"  {agent_name:15s}: {pnl_value:8.2f}\")\n",
    "\n",
    "# Win rates\n",
    "win_rates = metrics.win_rate(action_log, ref_prices)\n",
    "print(\"\\nAgent Win Rates:\")\n",
    "for agent_name, wr in win_rates.items():\n",
    "    print(f\"  {agent_name:15s}: {wr:.2%}\")\n",
    "\n",
    "# Directional accuracy per agent\n",
    "dir_acc_agents = metrics.per_agent_directional_accuracy(action_log, ref_prices)\n",
    "print(\"\\nAgent Directional Accuracy:\")\n",
    "for agent_name, acc in dir_acc_agents.items():\n",
    "    print(f\"  {agent_name:15s}: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='visualization'></a>\n",
    "## 8. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot price comparison\n",
    "fig, ax = plt.subplots(figsize=FIGSIZE_WIDE)\n",
    "\n",
    "ax.plot(ref_prices, label='Reference Prices', linewidth=2, alpha=0.7)\n",
    "ax.plot(sim_prices, label='Simulated Prices', linewidth=2, alpha=0.7, linestyle='--')\n",
    "\n",
    "ax.set_title('Price Comparison: Reference vs Simulated')\n",
    "ax.set_xlabel('Time Step')\n",
    "ax.set_ylabel('Price')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent comparison\n",
    "fig = plot_agent_comparison(action_log, ref_prices)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive dashboard (if visualizations module available)\n",
    "try:\n",
    "    fig = plot_comprehensive_dashboard(\n",
    "        prices=sim_prices,\n",
    "        action_log=action_log,\n",
    "        reference_prices=ref_prices\n",
    "    )\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Could not create comprehensive dashboard: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='takeaways'></a>\n",
    "## 9. Key Takeaways\n",
    "\n",
    "### Summary of Results\n",
    "\n",
    "1. **Data**: Successfully loaded and processed small dataset\n",
    "2. **Embedding**: Generated semantic embeddings for news text\n",
    "3. **Clustering**: Identified distinct latent event categories\n",
    "4. **Simulation**: Simulated multi-agent market dynamics\n",
    "5. **Performance**: Evaluated agents using multiple metrics\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "- **Directional Accuracy**: Indicates how well simulated prices match reference price movements\n",
    "- **Agent Performance**: Some agents outperform others based on strategy\n",
    "- **Cluster Quality**: Silhouette score indicates cluster cohesion\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Try FNSPID dataset for real-world validation (`02_fnspid_analysis.ipynb`)\n",
    "2. Compare different agent types (`03_agent_comparison.ipynb`)\n",
    "3. Analyze AI agents in depth (`04_ai_agents_analysis.ipynb`)\n",
    "4. Perform sensitivity analysis (`05_sensitivity_analysis.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results (optional)\n",
    "from src.result_cache import save_results\n",
    "\n",
    "results = {\n",
    "    'sim_prices': sim_prices,\n",
    "    'ref_prices': ref_prices,\n",
    "    'action_log': action_log,\n",
    "    'clusters': clusters,\n",
    "    'metrics': {\n",
    "        'directional_accuracy': dir_acc,\n",
    "        'volatility_clustering': vol_clust,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Uncomment to save:\n",
    "# cache_key = save_results(results, config)\n",
    "# print(f\"Results saved with cache_key: {cache_key}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Analysis Complete!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
